{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "In this exercise you will learn how to implement a feedforward neural network and train it with backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import multivariate_normal\n",
    "from numpy.random import uniform\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two helper functions \"init_toy_data\" and \"init_model\" to create a simple data set to work on and a 2 layer neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create toy data with categorical labels by sampling from different multivariate normal distributions for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_toy_data(num_samples,num_features, num_classes, seed=3):\n",
    "    # num_samples: number of samples *per class*\n",
    "    # num_features: number of features (excluding bias)\n",
    "    # num_classes: number of class labels\n",
    "    # seed: random seed\n",
    "    np.random.seed(seed)\n",
    "    X=np.zeros((num_samples*num_classes, num_features))\n",
    "    y=np.zeros(num_samples*num_classes)\n",
    "    for c in range(num_classes):\n",
    "        # initialize multivariate normal distribution for this class:\n",
    "        # choose a mean for each feature\n",
    "        means = uniform(low=-10, high=10, size=num_features)\n",
    "        # choose a variance for each feature\n",
    "        var = uniform(low=1.0, high=5, size=num_features)\n",
    "        # for simplicity, all features are uncorrelated (covariance between any two features is 0)\n",
    "        cov = var * np.eye(num_features)\n",
    "        # draw samples from normal distribution\n",
    "        X[c*num_samples:c*num_samples+num_samples,:] = multivariate_normal(means, cov, size=num_samples)\n",
    "        # set label\n",
    "        y[c*num_samples:c*num_samples+num_samples] = c\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.87161482  3.40442005 -4.77587701]\n",
      " [ 0.18344707  4.06926559 -5.52450275]\n",
      " [ 2.553425    6.05443298 -6.99528586]\n",
      " [ 0.3099948   4.26993708 -0.52119376]\n",
      " [ 2.72970654  0.85631895 -5.34968533]\n",
      " [ 0.65720002  1.62912085 -6.53962305]\n",
      " [-0.77004398  4.66909701 -0.99961344]\n",
      " [ 0.7359411   5.49983895 -5.70863867]\n",
      " [ 2.31571515  3.67111076 -5.8282157 ]\n",
      " [-0.07683167  1.50280437  0.04954387]\n",
      " [-2.39407907  0.46682477 -8.03658564]\n",
      " [-2.73608999 -1.62504729 -8.28919778]\n",
      " [-5.17933271 -0.57120207 -6.4571155 ]\n",
      " [-0.61417112  1.08346785 -5.17963337]\n",
      " [ 0.3202574   1.26215957 -2.27963095]\n",
      " [-4.60907573  0.80190444 -6.97226085]\n",
      " [-0.32659072 -3.84225973 -5.88595166]\n",
      " [ 0.74290915 -0.95334167 -1.80425265]\n",
      " [-1.64444549 -0.36778486 -6.03736941]\n",
      " [ 0.98482956  0.11564225 -6.85822626]]\n",
      "[[ 0.56327438  0.72058119  0.09191445]\n",
      " [ 0.23165606  0.98605791 -0.21556086]\n",
      " [ 1.37371494  1.77874688 -0.81964042]\n",
      " [ 0.29263763  1.06618721  1.83939655]\n",
      " [ 1.45866252 -0.29689051 -0.14375991]\n",
      " [ 0.45995092  0.01169381 -0.63249074]\n",
      " [-0.2278178   1.22557411  1.64290018]\n",
      " [ 0.49789513  1.55729423 -0.29118911]\n",
      " [ 1.25916592  0.82707235 -0.34030174]\n",
      " [ 0.10623142 -0.0387451   2.07380973]\n",
      " [-1.01041737 -0.45241782 -1.24732272]\n",
      " [-1.1752276  -1.28771459 -1.35107549]\n",
      " [-2.35259174 -0.86690802 -0.59860326]\n",
      " [-0.15270488 -0.20618862 -0.07391623]\n",
      " [ 0.29758303 -0.13483597  1.11717181]\n",
      " [-2.07779296 -0.31861855 -0.81018359]\n",
      " [-0.01412394 -2.17306051 -0.36401504]\n",
      " [ 0.50125293 -1.0194986   1.31241903]\n",
      " [-0.64917954 -0.78568234 -0.42620529]\n",
      " [ 0.61783096 -0.59264706 -0.76334734]]\n"
     ]
    }
   ],
   "source": [
    "X,y = init_toy_data(10,3,2)\n",
    "print(X)\n",
    "print(zscore(X,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(input_size,hidden_size,num_classes, seed=3):\n",
    "    # input size: number of input features\n",
    "    # hidden_size: number of units in the hidden layer\n",
    "    # num_classes: number of class labels, i.e., number of output units\n",
    "    np.random.seed(seed)\n",
    "    model = {}\n",
    "    # initialize weight matrices and biases randomly\n",
    "    model['W1'] = uniform(low=-1, high=1, size=(input_size, hidden_size))\n",
    "    model['b1'] = uniform(low=-1, high=1, size=hidden_size)\n",
    "    model['W2'] = uniform(low=-1, high=1, size=(hidden_size, num_classes))\n",
    "    model['b2'] = uniform(low=-1, high=1, size=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[ 0.39636145  1.09468144 -0.89360845  0.91815536]\n",
      " [ 0.94419323 -0.94027869  1.22268078  1.29597409]\n",
      " [-1.41577399  1.15477931 -0.62099631  0.08323307]\n",
      " [-1.35264614 -0.13598976 -1.14221784  0.26928935]\n",
      " [ 0.9352123   0.38225626  1.419864   -1.51152157]\n",
      " [ 0.49265316 -1.55544856  0.01427781 -1.0551303 ]]\n",
      "y: [0. 0. 1. 1. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# create toy data\n",
    "X,y= init_toy_data(2,4,3) # 2 samples per class; 4 features, 3 classes\n",
    "# Normalize data\n",
    "X = zscore(X, axis=0)\n",
    "print('X: ' + str(X))\n",
    "print('y: ' + str(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now initialise our neural net with one hidden layer consisting of $10$ units and and an output layer consisting of $3$ units. Here we expect (any number of) training samples with $4$ features. We do not apply any activation functions yet. The following figure shows a graphical representation of this neuronal net. \n",
    "<img src=\"nn.graphviz.png\"  width=\"30%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: {'W1': array([[ 0.10159581,  0.41629565, -0.41819052,  0.02165521,  0.78589391,\n",
      "         0.79258618, -0.74882938, -0.58551424, -0.89706559, -0.11838031],\n",
      "       [-0.94024758, -0.08633355,  0.2982881 , -0.44302543,  0.3525098 ,\n",
      "         0.18172563, -0.95203624,  0.11770818, -0.48149511, -0.16979761],\n",
      "       [-0.43294984,  0.38627584, -0.11909256, -0.68626452,  0.08929804,\n",
      "         0.56062953, -0.38727294, -0.55608423, -0.22405748,  0.8727673 ],\n",
      "       [ 0.95199084,  0.34476735,  0.80566822,  0.69150174, -0.24401192,\n",
      "        -0.81556598,  0.30682181,  0.11568152, -0.27687047, -0.54989099]]), 'b1': array([-0.18696017, -0.0621195 , -0.46152884, -0.41641445, -0.0846272 ,\n",
      "        0.72106783,  0.17250581, -0.43302428, -0.44404499, -0.09075585]), 'W2': array([[-0.58917931, -0.59724258,  0.02807012],\n",
      "       [-0.82554126, -0.03282894, -0.27564758],\n",
      "       [ 0.41537324,  0.49349245,  0.38218584],\n",
      "       [ 0.37836083, -0.25279975,  0.33626961],\n",
      "       [-0.32030267,  0.14558774, -0.34838568],\n",
      "       [-0.1097099 , -0.87694214, -0.51464916],\n",
      "       [ 0.94320521, -0.53883159,  0.38295502],\n",
      "       [ 0.30095372,  0.44787828, -0.04982278],\n",
      "       [ 0.19332755, -0.86606115, -0.85487572],\n",
      "       [-0.60204795, -0.69627801, -0.79979131]]), 'b2': array([-0.74141227,  0.10655546, -0.62437035])}\n",
      "model['W1'].shape: (4, 10)\n",
      "model['W2'].shape: (10, 3)\n",
      "model['b1'].shape: (10,)\n",
      "model['b12'].shape: (3,)\n",
      "number of parameters: 83\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = init_model(input_size=4, hidden_size=10, num_classes=3)\n",
    "\n",
    "print('model: ' + str(model))\n",
    "print('model[\\'W1\\'].shape: ' + str(model['W1'].shape))\n",
    "print('model[\\'W2\\'].shape: ' + str(model['W2'].shape))\n",
    "print('model[\\'b1\\'].shape: ' + str(model['b1'].shape))\n",
    "print('model[\\'b12\\'].shape: ' + str(model['b2'].shape))\n",
    "print('number of parameters: ' + str((model['W1'].shape[0] * model['W1'].shape[1]) + \n",
    "     np.sum(model['W2'].shape[0] * model['W2'].shape[1]) + \n",
    "     np.sum(model['b1'].shape[0]) +\n",
    "     np.sum(model['b2'].shape[0] )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise 1</b>: Implement softmax layer.\n",
    "\n",
    "Implement the softmax function given by \n",
    "\n",
    "$softmax(x_i) = \\frac{e^{x_i}}{{\\sum_{j\\in 1...J}e^{x_j}}}$, \n",
    "\n",
    "where $J$ is the total number of classes, i.e. the length of  **x** .\n",
    "\n",
    "Note: Implement the function such that it takes a matrix X of shape (N, J) as input rather than a single instance **x**; N is the number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    #######################################\n",
    "    # INSERT YOUR CODE HERE\n",
    "    #######################################\n",
    "    result=np.zeros_like(X)\n",
    "    for i,row in enumerate(X):\n",
    "        result[i]=np.exp(row)/np.sum(np.exp(row))\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if everything is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing successful.\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0.1, 0.7],[0.7,0.4]])\n",
    "exact_softmax = np.array([[ 0.35434369,  0.64565631],\n",
    "                         [ 0.57444252,  0.42555748]])\n",
    "sm = softmax(x)\n",
    "difference = np.sum(np.abs(exact_softmax - sm))\n",
    "try:\n",
    "    assert difference < 0.000001   \n",
    "    print(\"Testing successful.\")\n",
    "except:\n",
    "    print(\"Tests failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise 2</b>: Implement the forward propagation algorithm for the model defined above.\n",
    "\n",
    "The activation function of the hidden neurons is a Rectified Linear Unit $relu(x)=max(0,x)$ (to be applied element-wise to the hidden units)\n",
    "The activation function of the output layer is a softmax function as (as implemented in Exercise 1).\n",
    "\n",
    "The function should return both the activation of the hidden units (after having applied the $relu$ activation function) (shape: $(N, num\\_hidden)$) and the softmax model output (shape: $(N, num\\_classes)$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X,model):\n",
    "    ###############################################\n",
    "    # INSERT YOUR CODE HERE                       #\n",
    "    ###############################################\n",
    "    a1 = np.maximum(0,np.add(np.matmul(X,model['W1']),model['b1']))\n",
    "    \n",
    "    a2 = np.add(np.matmul(a1,model['W2']), model['b2'])\n",
    "    out = softmax(a2)\n",
    "    return a1,out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing successful.\n"
     ]
    }
   ],
   "source": [
    "acts,probs = forward_prop(X, model)\n",
    "correct_probs = np.array([[0.22836388, 0.51816433, 0.25347179],\n",
    "                            [0.15853289, 0.33057078, 0.51089632],\n",
    "                            [0.40710319, 0.41765056, 0.17524624],\n",
    "                            [0.85151353, 0.03656425, 0.11192222],\n",
    "                            [0.66016592, 0.19839791, 0.14143618],\n",
    "                            [0.70362036, 0.08667923, 0.20970041]])\n",
    "\n",
    "# the difference should be very small.\n",
    "difference =  np.sum(np.abs(probs - correct_probs))\n",
    "\n",
    "try:\n",
    "    assert probs.shape==(X.shape[0],len(set(y)))\n",
    "    assert difference < 0.00001   \n",
    "    print(\"Testing successful.\")\n",
    "except:\n",
    "    print(\"Tests failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\cog\\anaconda3\\lib\\site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\cog\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\cog\\anaconda3\\lib\\site-packages (from keras) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\cog\\anaconda3\\lib\\site-packages (from keras) (1.6.2)\n",
      "Requirement already satisfied: six in c:\\users\\cog\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.5.0-cp38-cp38-win_amd64.whl (422.6 MB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\cog\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\cog\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-3.17.3-py2.py3-none-any.whl (173 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Using cached keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Using cached numpy-1.19.5-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorboard~=2.5\n",
      "  Using cached tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\cog\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Using cached h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\cog\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Using cached grpcio-1.34.1-cp38-cp38-win_amd64.whl (2.9 MB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.31.0-py2.py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\cog\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.25.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\cog\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\cog\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (52.0.0.post20210125)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cog\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cog\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\cog\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\cog\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (4.0.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=84dcc439e37f6d938d87af156c829dde4f5686e15ebca21b2061ed5366c66021\n",
      "  Stored in directory: c:\\users\\cog\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-nightly, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.1\n",
      "    Uninstalling numpy-1.20.1:\n",
      "      Successfully uninstalled numpy-1.20.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "Successfully installed absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 flatbuffers-1.12 gast-0.4.0 google-auth-1.31.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise 3:</b> How would you train the above defined neural network? Which loss-function would you use? You do not need to implement this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Part 2 (Neural Net using Keras)</b>\n",
    "\n",
    "Instead of implementing the model learning ourselves, we can use the neural network library Keras for Python (https://keras.io/). Keras is an abstraction layer that either builds on top of Theano or Google's Tensorflow. So please install Keras and Tensorflow/Theano for this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise 4:</b>\n",
    "    Implement the same model as above using Keras:\n",
    "    \n",
    "    ** 1 hidden layer à 10 units\n",
    "    ** softmax output layer à three units\n",
    "    ** 4 input features\n",
    "    \n",
    "Compile the model using categorical cross-entropy (also referred to as 'softmax-loss') as loss function and using categorical crossentropy together categorical accuracy as metrics for runtime evaluation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Activation\n",
    "\n",
    "# define the model \n",
    "################################################\n",
    "# INSERT YOUR CODE HERE                        #\n",
    "################################################\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10,input_dim = 4,activation = 'relu'))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "################################################\n",
    "# INSERT YOUR CODE HERE                        #\n",
    "################################################\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description of the current network can always be looked at via the summary method. The layers can be accessed via model.layers and weights can be obtained with the method get_weights. Check if your model is as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check model architecture and initial weights.\n",
    "\n",
    "#############################################\n",
    "# INSERT YOUR CODE HERE                     #\n",
    "#############################################\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.34277642, -0.5813798 ,  0.4183488 , -0.46621323, -0.4852491 ,\n",
      "        -0.3190562 , -0.4091835 , -0.00275517, -0.15084428,  0.21051723],\n",
      "       [-0.3190904 ,  0.63825154,  0.6236813 ,  0.475106  , -0.12454623,\n",
      "        -0.40144983, -0.41297394, -0.32373804, -0.19516036, -0.3453104 ],\n",
      "       [-0.16077918, -0.39110193,  0.15646493, -0.51652646, -0.44150442,\n",
      "         0.3281082 ,  0.07540148,  0.05318654,  0.3246246 , -0.6261151 ],\n",
      "       [-0.14124262, -0.6382946 , -0.3699037 , -0.36522517, -0.02580839,\n",
      "        -0.07660466,  0.4276508 , -0.09739679, -0.16129503,  0.3242061 ]],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]\n",
      "[array([[ 0.42243457,  0.49078906, -0.10360295],\n",
      "       [-0.37795016, -0.5292926 , -0.06808525],\n",
      "       [-0.08380789, -0.13367432, -0.24949497],\n",
      "       [ 0.2637216 , -0.4528955 , -0.16099262],\n",
      "       [ 0.47686303, -0.38811514, -0.04353267],\n",
      "       [ 0.17042887,  0.307509  ,  0.44068336],\n",
      "       [-0.17505306,  0.20978212,  0.5286193 ],\n",
      "       [-0.0380348 ,  0.08377641,  0.47936225],\n",
      "       [-0.06162447,  0.56394565,  0.17119241],\n",
      "       [-0.40547013,  0.36189747,  0.52313244]], dtype=float32), array([0., 0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Exercise 5:</b> Train the model on the toy data set generated below: \n",
    "\n",
    "Hints: \n",
    "\n",
    "* Keras expects one-hot-coded labels \n",
    "\n",
    "* Don't forget to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = init_toy_data(1000,4,3, seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data instance before normalization: [-0.32467846  3.98578199 -4.76683151  0.15729264]\n",
      "Data instance after normalization: [ 0.52324084  1.27080131  0.27083063 -0.85289313]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "print('Data instance before normalization: '+str(X[0]))\n",
    "X = sc.fit_transform(X)\n",
    "print('Data instance after normalization: '+str(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels before encoding : [0. 0. 0. ... 2. 2. 2.]\n",
      "Labels after encoding : [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "print('Labels before encoding : ' + str(y))\n",
    "y = ohe.fit_transform(y.reshape(-1,1)).toarray()\n",
    "print('Labels after encoding : ' + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 18s 1ms/step - loss: 0.9229 - accuracy: 0.5595\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.9433\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1690 - accuracy: 0.9842\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9928\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9897\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 0s 956us/step - loss: 0.0628 - accuracy: 0.9913\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 0s 984us/step - loss: 0.0455 - accuracy: 0.9939\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 0s 956us/step - loss: 0.0464 - accuracy: 0.9914\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0354 - accuracy: 0.9927\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f32602b3a0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
